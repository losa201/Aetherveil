#!/usr/bin/env python3
"""
Aetherveil Red Team Pentester Agent
A defensive security testing agent for authorized vulnerability assessment.

This agent is designed for defensive security purposes only and must only be used
on systems you own or have explicit written permission to test.
"""

import os
import json
import asyncio
import aiohttp
import logging
import time
import random
import urllib.robotparser
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from urllib.parse import urljoin, urlparse
import yaml
from google.cloud import bigquery, pubsub_v1, firestore
import requests

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class VulnerabilityFinding:
    """Structure for vulnerability findings"""
    finding_id: str
    timestamp: datetime
    target_url: str
    vulnerability_type: str
    severity: str  # critical, high, medium, low
    description: str
    evidence: str
    remediation: str
    cve_references: List[str]
    confidence: str  # high, medium, low
    scanner_version: str

@dataclass
class ScanScope:
    """Structure for scan scope definition"""
    program_name: str
    in_scope_domains: List[str]
    out_of_scope_domains: List[str]
    allowed_ports: List[int]
    scan_types: List[str]
    rate_limit_per_second: float
    respect_robots_txt: bool
    contact_email: str

class RateLimiter:
    """Rate limiting functionality"""
    
    def __init__(self, max_requests_per_second: float):
        self.max_requests_per_second = max_requests_per_second
        self.min_interval = 1.0 / max_requests_per_second if max_requests_per_second > 0 else 1.0
        self.last_request_time = 0
        
    async def wait_if_needed(self):
        """Wait if necessary to respect rate limits"""
        now = time.time()
        time_since_last = now - self.last_request_time
        
        if time_since_last < self.min_interval:
            wait_time = self.min_interval - time_since_last
            await asyncio.sleep(wait_time)
        
        self.last_request_time = time.time()

class RobotsChecker:
    """Check robots.txt compliance"""
    
    def __init__(self):
        self.robots_cache = {}
        
    def can_fetch(self, url: str, user_agent: str = "*") -> bool:
        """Check if URL can be fetched according to robots.txt"""
        try:
            parsed_url = urlparse(url)
            base_url = f"{parsed_url.scheme}://{parsed_url.netloc}"
            
            if base_url not in self.robots_cache:
                robots_url = urljoin(base_url, "/robots.txt")
                rp = urllib.robotparser.RobotFileParser()
                rp.set_url(robots_url)
                try:
                    rp.read()
                    self.robots_cache[base_url] = rp
                except:
                    # If robots.txt can't be read, assume scanning is allowed
                    self.robots_cache[base_url] = None
            
            robots_parser = self.robots_cache[base_url]
            if robots_parser:
                return robots_parser.can_fetch(user_agent, url)
            return True
            
        except Exception as e:
            logger.warning(f"Error checking robots.txt for {url}: {e}")
            return True

class SecurityScanner:
    """Core security scanning functionality"""
    
    def __init__(self, scope: ScanScope):
        self.scope = scope
        self.rate_limiter = RateLimiter(scope.rate_limit_per_second)
        self.robots_checker = RobotsChecker() if scope.respect_robots_txt else None
        self.findings: List[VulnerabilityFinding] = []
        
    async def scan_target(self, target_url: str) -> List[VulnerabilityFinding]:
        """Scan a target URL for vulnerabilities"""
        findings = []
        
        # Check if scanning is allowed
        if self.robots_checker and not self.robots_checker.can_fetch(target_url):
            logger.info(f"Skipping {target_url} due to robots.txt restrictions")
            return findings
            
        # Rate limiting
        await self.rate_limiter.wait_if_needed()
        
        logger.info(f"Scanning {target_url}")
        
        # Perform different types of scans based on scope
        if "xss" in self.scope.scan_types:
            findings.extend(await self.scan_xss(target_url))
        if "sql_injection" in self.scope.scan_types:
            findings.extend(await self.scan_sql_injection(target_url))
        if "ssrf" in self.scope.scan_types:
            findings.extend(await self.scan_ssrf(target_url))
        if "rce" in self.scope.scan_types:
            findings.extend(await self.scan_rce(target_url))
        if "directory_traversal" in self.scope.scan_types:
            findings.extend(await self.scan_directory_traversal(target_url))
        
        return findings
    
    async def scan_xss(self, target_url: str) -> List[VulnerabilityFinding]:
        """Scan for Cross-Site Scripting vulnerabilities"""
        findings = []
        
        # Basic XSS payloads (safe, non-malicious)
        xss_payloads = [
            "<script>console.log('XSS-Test')</script>",
            "';alert('XSS-Test');//",
            "\"><script>console.log('XSS-Test')</script>",
            "javascript:console.log('XSS-Test')"
        ]
        
        try:
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=10)) as session:
                for payload in xss_payloads:
                    # Test GET parameters
                    test_url = f"{target_url}?test={payload}"
                    
                    try:
                        await self.rate_limiter.wait_if_needed()
                        async with session.get(test_url) as response:
                            content = await response.text()
                            
                            # Check if payload is reflected unescaped
                            if payload in content and "XSS-Test" in content:
                                finding = VulnerabilityFinding(
                                    finding_id=f"xss_{int(time.time())}_{random.randint(1000,9999)}",
                                    timestamp=datetime.now(timezone.utc),
                                    target_url=test_url,
                                    vulnerability_type="Cross-Site Scripting (XSS)",
                                    severity="medium",
                                    description=f"Potential XSS vulnerability detected. Payload reflected: {payload[:50]}...",
                                    evidence=f"Response contains unescaped payload: {payload}",
                                    remediation="Implement proper input validation and output encoding",
                                    cve_references=["CWE-79"],
                                    confidence="medium",
                                    scanner_version="1.0.0"
                                )
                                findings.append(finding)
                                logger.warning(f"Potential XSS found: {test_url}")
                                
                    except Exception as e:
                        logger.debug(f"Error testing XSS on {test_url}: {e}")
                        
        except Exception as e:
            logger.error(f"Error in XSS scanning: {e}")
            
        return findings
    
    async def scan_sql_injection(self, target_url: str) -> List[VulnerabilityFinding]:
        """Scan for SQL Injection vulnerabilities"""
        findings = []
        
        # Safe SQL injection test payloads
        sql_payloads = [
            "' OR '1'='1",
            "' UNION SELECT 1--",
            "'; WAITFOR DELAY '00:00:05'--",
            "' AND SLEEP(5)--"
        ]
        
        try:
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=15)) as session:
                for payload in sql_payloads:
                    test_url = f"{target_url}?id={payload}"
                    
                    try:
                        await self.rate_limiter.wait_if_needed()
                        start_time = time.time()
                        
                        async with session.get(test_url) as response:
                            content = await response.text()
                            response_time = time.time() - start_time
                            
                            # Check for SQL error messages
                            sql_errors = [
                                "mysql_fetch_array",
                                "ORA-01756",
                                "Microsoft OLE DB Provider",
                                "PostgreSQL query failed",
                                "SQLServer JDBC Driver"
                            ]
                            
                            for error in sql_errors:
                                if error.lower() in content.lower():
                                    finding = VulnerabilityFinding(
                                        finding_id=f"sqli_{int(time.time())}_{random.randint(1000,9999)}",
                                        timestamp=datetime.now(timezone.utc),
                                        target_url=test_url,
                                        vulnerability_type="SQL Injection",
                                        severity="high",
                                        description=f"Potential SQL injection detected. Error message: {error}",
                                        evidence=f"SQL error in response: {error}",
                                        remediation="Use parameterized queries and input validation",
                                        cve_references=["CWE-89"],
                                        confidence="high",
                                        scanner_version="1.0.0"
                                    )
                                    findings.append(finding)
                                    logger.warning(f"Potential SQL injection found: {test_url}")
                                    break
                            
                            # Check for time-based SQL injection (if response takes too long)
                            if "SLEEP" in payload and response_time > 4:
                                finding = VulnerabilityFinding(
                                    finding_id=f"sqli_time_{int(time.time())}_{random.randint(1000,9999)}",
                                    timestamp=datetime.now(timezone.utc),
                                    target_url=test_url,
                                    vulnerability_type="Time-based SQL Injection",
                                    severity="high",
                                    description=f"Time-based SQL injection detected. Response time: {response_time:.2f}s",
                                    evidence=f"Response delayed by {response_time:.2f} seconds",
                                    remediation="Use parameterized queries and input validation",
                                    cve_references=["CWE-89"],
                                    confidence="medium",
                                    scanner_version="1.0.0"
                                )
                                findings.append(finding)
                                logger.warning(f"Time-based SQL injection found: {test_url}")
                                
                    except Exception as e:
                        logger.debug(f"Error testing SQL injection on {test_url}: {e}")
                        
        except Exception as e:
            logger.error(f"Error in SQL injection scanning: {e}")
            
        return findings
    
    async def scan_ssrf(self, target_url: str) -> List[VulnerabilityFinding]:
        """Scan for Server-Side Request Forgery vulnerabilities"""
        findings = []
        
        # Safe SSRF test payloads (using safe endpoints)
        ssrf_payloads = [
            "http://127.0.0.1:80",
            "http://localhost:22",
            "file:///etc/passwd",
            "http://169.254.169.254/latest/meta-data/"  # AWS metadata (safe to test)
        ]
        
        try:
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=10)) as session:
                for payload in ssrf_payloads:
                    test_url = f"{target_url}?url={payload}"
                    
                    try:
                        await self.rate_limiter.wait_if_needed()
                        async with session.get(test_url) as response:
                            content = await response.text()
                            
                            # Check for SSRF indicators
                            ssrf_indicators = [
                                "root:x:0:0",  # /etc/passwd content
                                "ami-id",      # AWS metadata
                                "Connection refused",
                                "SSH-2.0"      # SSH banner
                            ]
                            
                            for indicator in ssrf_indicators:
                                if indicator in content:
                                    finding = VulnerabilityFinding(
                                        finding_id=f"ssrf_{int(time.time())}_{random.randint(1000,9999)}",
                                        timestamp=datetime.now(timezone.utc),
                                        target_url=test_url,
                                        vulnerability_type="Server-Side Request Forgery (SSRF)",
                                        severity="high",
                                        description=f"Potential SSRF detected. Indicator: {indicator}",
                                        evidence=f"Response contains: {indicator}",
                                        remediation="Implement URL validation and whitelist allowed destinations",
                                        cve_references=["CWE-918"],
                                        confidence="medium",
                                        scanner_version="1.0.0"
                                    )
                                    findings.append(finding)
                                    logger.warning(f"Potential SSRF found: {test_url}")
                                    break
                                    
                    except Exception as e:
                        logger.debug(f"Error testing SSRF on {test_url}: {e}")
                        
        except Exception as e:
            logger.error(f"Error in SSRF scanning: {e}")
            
        return findings
    
    async def scan_rce(self, target_url: str) -> List[VulnerabilityFinding]:
        """Scan for Remote Code Execution vulnerabilities"""
        findings = []
        
        # Safe RCE test payloads (read-only operations)
        rce_payloads = [
            "; echo 'RCE-TEST-MARKER'",
            "| whoami",
            "`pwd`",
            "$(echo RCE-TEST)"
        ]
        
        try:
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=10)) as session:
                for payload in rce_payloads:
                    test_url = f"{target_url}?cmd={payload}"
                    
                    try:
                        await self.rate_limiter.wait_if_needed()
                        async with session.get(test_url) as response:
                            content = await response.text()
                            
                            # Check for RCE indicators
                            if "RCE-TEST" in content or "RCE-TEST-MARKER" in content:
                                finding = VulnerabilityFinding(
                                    finding_id=f"rce_{int(time.time())}_{random.randint(1000,9999)}",
                                    timestamp=datetime.now(timezone.utc),
                                    target_url=test_url,
                                    vulnerability_type="Remote Code Execution (RCE)",
                                    severity="critical",
                                    description="Potential RCE vulnerability detected",
                                    evidence=f"Command output detected in response: {payload}",
                                    remediation="Implement strict input validation and avoid system command execution",
                                    cve_references=["CWE-78"],
                                    confidence="high",
                                    scanner_version="1.0.0"
                                )
                                findings.append(finding)
                                logger.critical(f"Potential RCE found: {test_url}")
                                
                    except Exception as e:
                        logger.debug(f"Error testing RCE on {test_url}: {e}")
                        
        except Exception as e:
            logger.error(f"Error in RCE scanning: {e}")
            
        return findings
    
    async def scan_directory_traversal(self, target_url: str) -> List[VulnerabilityFinding]:
        """Scan for Directory Traversal vulnerabilities"""
        findings = []
        
        # Directory traversal payloads
        traversal_payloads = [
            "../../../etc/passwd",
            "..\\..\\..\\windows\\system32\\drivers\\etc\\hosts",
            "%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd",
            "....//....//....//etc/passwd"
        ]
        
        try:
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=10)) as session:
                for payload in traversal_payloads:
                    test_url = f"{target_url}?file={payload}"
                    
                    try:
                        await self.rate_limiter.wait_if_needed()
                        async with session.get(test_url) as response:
                            content = await response.text()
                            
                            # Check for file content indicators
                            file_indicators = [
                                "root:x:0:0",  # /etc/passwd
                                "# localhost name resolution",  # hosts file
                                "[HKEY_LOCAL_MACHINE"  # Windows registry
                            ]
                            
                            for indicator in file_indicators:
                                if indicator in content:
                                    finding = VulnerabilityFinding(
                                        finding_id=f"traversal_{int(time.time())}_{random.randint(1000,9999)}",
                                        timestamp=datetime.now(timezone.utc),
                                        target_url=test_url,
                                        vulnerability_type="Directory Traversal",
                                        severity="high",
                                        description=f"Directory traversal detected. File content: {indicator[:50]}...",
                                        evidence=f"System file content in response: {indicator}",
                                        remediation="Implement proper file path validation and access controls",
                                        cve_references=["CWE-22"],
                                        confidence="high",
                                        scanner_version="1.0.0"
                                    )
                                    findings.append(finding)
                                    logger.warning(f"Directory traversal found: {test_url}")
                                    break
                                    
                    except Exception as e:
                        logger.debug(f"Error testing directory traversal on {test_url}: {e}")
                        
        except Exception as e:
            logger.error(f"Error in directory traversal scanning: {e}")
            
        return findings

class RedTeamPentesterAgent:
    """Main Red Team Pentester Agent"""
    
    def __init__(self):
        self.project_id = os.getenv('PROJECT_ID', 'tidy-computing-465909-i3')
        self.bigquery_client = bigquery.Client(project=self.project_id)
        self.pubsub_client = pubsub_v1.PublisherClient()
        self.firestore_client = firestore.Client(project=self.project_id)
        
        # Topics for reporting
        self.findings_topic = f"projects/{self.project_id}/topics/aetherveil-security-findings"
        self.alerts_topic = f"projects/{self.project_id}/topics/aetherveil-security-alerts"
        
    def parse_scope_file(self, scope_data: Dict[str, Any]) -> ScanScope:
        """Parse scope configuration from JSON/YAML"""
        return ScanScope(
            program_name=scope_data.get('program_name', 'Unknown'),
            in_scope_domains=scope_data.get('in_scope_domains', []),
            out_of_scope_domains=scope_data.get('out_of_scope_domains', []),
            allowed_ports=scope_data.get('allowed_ports', [80, 443]),
            scan_types=scope_data.get('scan_types', ['xss', 'sql_injection']),
            rate_limit_per_second=scope_data.get('rate_limit_per_second', 0.5),
            respect_robots_txt=scope_data.get('respect_robots_txt', True),
            contact_email=scope_data.get('contact_email', '')
        )
    
    def generate_scan_targets(self, scope: ScanScope) -> List[str]:
        """Generate list of URLs to scan based on scope"""
        targets = []
        
        for domain in scope.in_scope_domains:
            # Skip if domain is in out-of-scope list
            if domain in scope.out_of_scope_domains:
                continue
                
            # Generate URLs for different ports
            for port in scope.allowed_ports:
                protocol = "https" if port == 443 else "http"
                if port in [80, 443]:
                    targets.append(f"{protocol}://{domain}")
                else:
                    targets.append(f"{protocol}://{domain}:{port}")
                    
                # Add common paths
                common_paths = [
                    "/admin", "/login", "/search", "/upload", 
                    "/api/v1", "/api/v2", "/dashboard"
                ]
                
                for path in common_paths:
                    if port in [80, 443]:
                        targets.append(f"{protocol}://{domain}{path}")
                    else:
                        targets.append(f"{protocol}://{domain}:{port}{path}")
        
        return targets
    
    async def run_scan(self, scope_config: Dict[str, Any]) -> Dict[str, Any]:
        """Run a complete security scan"""
        logger.info("Starting Red Team Pentester scan")
        
        # Parse scope
        scope = self.parse_scope_file(scope_config)
        logger.info(f"Scanning program: {scope.program_name}")
        
        # Generate targets
        targets = self.generate_scan_targets(scope)
        logger.info(f"Generated {len(targets)} targets to scan")
        
        # Initialize scanner
        scanner = SecurityScanner(scope)
        
        all_findings = []
        scan_start_time = datetime.now(timezone.utc)
        
        # Scan each target
        for target in targets:
            try:
                findings = await scanner.scan_target(target)
                all_findings.extend(findings)
                logger.info(f"Scanned {target}: {len(findings)} findings")
                
            except Exception as e:
                logger.error(f"Error scanning {target}: {e}")
        
        scan_end_time = datetime.now(timezone.utc)
        scan_duration = (scan_end_time - scan_start_time).total_seconds()
        
        # Report findings
        await self.report_findings(all_findings, scope, scan_duration)
        
        return {
            "scan_id": f"scan_{int(time.time())}",
            "program_name": scope.program_name,
            "targets_scanned": len(targets),
            "findings_count": len(all_findings),
            "scan_duration_seconds": scan_duration,
            "critical_findings": len([f for f in all_findings if f.severity == "critical"]),
            "high_findings": len([f for f in all_findings if f.severity == "high"]),
            "medium_findings": len([f for f in all_findings if f.severity == "medium"]),
            "low_findings": len([f for f in all_findings if f.severity == "low"])
        }
    
    async def report_findings(self, findings: List[VulnerabilityFinding], scope: ScanScope, scan_duration: float):
        """Report findings to BigQuery and Pub/Sub"""
        
        # Store findings in BigQuery
        if findings:
            await self.store_findings_bigquery(findings, scope, scan_duration)
            
        # Send alerts for critical/high severity findings
        critical_high_findings = [f for f in findings if f.severity in ["critical", "high"]]
        if critical_high_findings:
            await self.send_security_alerts(critical_high_findings, scope)
        
        # Store scan metadata in Firestore
        await self.store_scan_metadata(findings, scope, scan_duration)
    
    async def store_findings_bigquery(self, findings: List[VulnerabilityFinding], scope: ScanScope, scan_duration: float):
        """Store findings in BigQuery for analysis"""
        try:
            dataset_id = "security_analytics"
            table_id = "vulnerability_findings"
            table_ref = self.bigquery_client.dataset(dataset_id).table(table_id)
            
            # Create table if it doesn't exist
            try:
                self.bigquery_client.get_table(table_ref)
            except:
                schema = [
                    bigquery.SchemaField("finding_id", "STRING", mode="REQUIRED"),
                    bigquery.SchemaField("timestamp", "TIMESTAMP", mode="REQUIRED"),
                    bigquery.SchemaField("program_name", "STRING", mode="REQUIRED"),
                    bigquery.SchemaField("target_url", "STRING", mode="REQUIRED"),
                    bigquery.SchemaField("vulnerability_type", "STRING", mode="REQUIRED"),
                    bigquery.SchemaField("severity", "STRING", mode="REQUIRED"),
                    bigquery.SchemaField("description", "STRING", mode="REQUIRED"),
                    bigquery.SchemaField("evidence", "STRING", mode="NULLABLE"),
                    bigquery.SchemaField("remediation", "STRING", mode="NULLABLE"),
                    bigquery.SchemaField("cve_references", "STRING", mode="REPEATED"),
                    bigquery.SchemaField("confidence", "STRING", mode="REQUIRED"),
                    bigquery.SchemaField("scanner_version", "STRING", mode="REQUIRED"),
                ]
                
                table = bigquery.Table(table_ref, schema=schema)
                table.time_partitioning = bigquery.TimePartitioning(
                    type_=bigquery.TimePartitioningType.DAY,
                    field="timestamp"
                )
                self.bigquery_client.create_table(table)
                logger.info(f"Created BigQuery table: {dataset_id}.{table_id}")
            
            # Insert findings
            rows_to_insert = []
            for finding in findings:
                row = asdict(finding)
                row['program_name'] = scope.program_name
                row['timestamp'] = finding.timestamp.isoformat()
                rows_to_insert.append(row)
            
            errors = self.bigquery_client.insert_rows_json(table_ref, rows_to_insert)
            if errors:
                logger.error(f"BigQuery insert errors: {errors}")
            else:
                logger.info(f"Stored {len(findings)} findings in BigQuery")
                
        except Exception as e:
            logger.error(f"Error storing findings in BigQuery: {e}")
    
    async def send_security_alerts(self, critical_findings: List[VulnerabilityFinding], scope: ScanScope):
        """Send alerts for critical security findings"""
        try:
            alert_data = {
                "alert_type": "security_vulnerability",
                "program_name": scope.program_name,
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "critical_findings_count": len([f for f in critical_findings if f.severity == "critical"]),
                "high_findings_count": len([f for f in critical_findings if f.severity == "high"]),
                "findings": [asdict(f) for f in critical_findings[:5]]  # First 5 findings
            }
            
            message = json.dumps(alert_data).encode('utf-8')
            future = self.pubsub_client.publish(self.alerts_topic, message)
            message_id = future.result()
            
            logger.info(f"Published security alert: {message_id}")
            
        except Exception as e:
            logger.error(f"Error sending security alerts: {e}")
    
    async def store_scan_metadata(self, findings: List[VulnerabilityFinding], scope: ScanScope, scan_duration: float):
        """Store scan metadata in Firestore"""
        try:
            scan_doc = {
                "scan_id": f"scan_{int(time.time())}",
                "program_name": scope.program_name,
                "timestamp": datetime.now(timezone.utc),
                "scan_duration_seconds": scan_duration,
                "targets_count": len(scope.in_scope_domains),
                "findings_count": len(findings),
                "severity_breakdown": {
                    "critical": len([f for f in findings if f.severity == "critical"]),
                    "high": len([f for f in findings if f.severity == "high"]),
                    "medium": len([f for f in findings if f.severity == "medium"]),
                    "low": len([f for f in findings if f.severity == "low"])
                },
                "scan_types": scope.scan_types,
                "rate_limit": scope.rate_limit_per_second
            }
            
            self.firestore_client.collection('red_team_scans').add(scan_doc)
            logger.info("Stored scan metadata in Firestore")
            
        except Exception as e:
            logger.error(f"Error storing scan metadata: {e}")

async def main():
    """Main entry point"""
    agent = RedTeamPentesterAgent()
    
    # Example scope configuration
    scope_config = {
        "program_name": "Example HackerOne Program",
        "in_scope_domains": ["example.com", "api.example.com"],
        "out_of_scope_domains": ["internal.example.com"],
        "allowed_ports": [80, 443],
        "scan_types": ["xss", "sql_injection", "ssrf", "rce", "directory_traversal"],
        "rate_limit_per_second": 0.5,
        "respect_robots_txt": True,
        "contact_email": "security@example.com"
    }
    
    # Run scan
    result = await agent.run_scan(scope_config)
    logger.info(f"Scan completed: {result}")

if __name__ == "__main__":
    asyncio.run(main())